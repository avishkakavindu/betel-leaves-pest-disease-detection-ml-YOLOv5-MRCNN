{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Betel Vine Pest Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### !!! Run only once!!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
      "fatal: Could not parse object 'fbe67e465375231474a2ad80a4389efc77ecff99'.\n"
     ]
    }
   ],
   "source": [
    "# clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\yolov5\n"
     ]
    }
   ],
   "source": [
    "# move to yolov5 dir\n",
    "%cd yolov5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# install dependencies as necessary\n",
    "!pip install -qr requirements.txt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (4.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: torch in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (2.29.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from torchvision) (9.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: albumentations in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from opencv-python) (1.21.6)\n",
      "Requirement already satisfied: scipy in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from albumentations) (1.4.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from albumentations) (6.0)\n",
      "Requirement already satisfied: qudida>=0.0.4 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from albumentations) (4.7.0.72)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from qudida>=0.0.4->albumentations) (4.5.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.6.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (9.5.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.28.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2021.11.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\acer\\documents\\my mini projects\\ml\\betel leaves\\venv\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install torchvision\n",
    "! pip install torch torchvision --upgrade\n",
    "! pip install opencv-python albumentations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.13.1+cpu CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.downloads import attempt_download  # to download models/datasets\n",
    "\n",
    "# clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\n"
     ]
    }
   ],
   "source": [
    "# move back to root dir\n",
    "%cd .."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Validation Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# Define the path to your dataset\n",
    "PEST_DATASET = '../../datasets/pests'\n",
    "# Define the path to the directory where you want to save the train and test sets\n",
    "TRAIN_DIR = f'{PEST_DATASET}/train'\n",
    "TEST_DIR = f'{PEST_DATASET}/test'\n",
    "CLASSES_FILE_PATH = '../datasets/pests/classes.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Create the train and test directories and their subdirectories\n",
    "for dir in [TRAIN_DIR, TEST_DIR]:\n",
    "    os.makedirs(os.path.join(dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(dir, 'labels'), exist_ok=True)\n",
    "\n",
    "# Get a list of all the image files in the dataset directory\n",
    "image_files = [f for f in os.listdir(PEST_DATASET) if f.endswith('.jpg')]\n",
    "\n",
    "# Shuffle the list of image files\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Split the image files into train and test sets\n",
    "split_index = int(len(image_files) * 0.8)\n",
    "train_files = image_files[:split_index]\n",
    "test_files = image_files[split_index:]\n",
    "\n",
    "# Move the train images and annotations to the train directories\n",
    "for file_name in train_files:\n",
    "    image_path = os.path.join(PEST_DATASET, file_name)\n",
    "    label_path = os.path.join(PEST_DATASET, file_name.replace('.jpg', '.txt'))\n",
    "    shutil.copy(image_path, os.path.join(TRAIN_DIR, 'images', file_name))\n",
    "    shutil.copy(label_path, os.path.join(TRAIN_DIR, 'labels', file_name.replace('.jpg', '.txt')))\n",
    "\n",
    "# Move the test images and annotations to the test directories\n",
    "for file_name in test_files:\n",
    "    image_path = os.path.join(PEST_DATASET, file_name)\n",
    "    label_path = os.path.join(PEST_DATASET, file_name.replace('.jpg', '.txt'))\n",
    "    shutil.copy(image_path, os.path.join(TEST_DIR, 'images', file_name))\n",
    "    shutil.copy(label_path, os.path.join(TEST_DIR, 'labels', file_name.replace('.jpg', '.txt')))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setting up dataset paths for YOLO model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working dir:  C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "# Load the YAML file\n",
    "YAML_PATH = '../pest_detection/yolov5/data/coco128.yaml'\n",
    "NEW_YAML_PATH = '../pest_detection/yolov5/data/custom_data.yaml'\n",
    "\n",
    "current_path = os.getcwd()\n",
    "print('Current working dir: ', current_path)\n",
    "\n",
    "with open(YAML_PATH, 'r', encoding='utf-8') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "\n",
    "# Define the mapping between class names and labels\n",
    "with open(CLASSES_FILE_PATH, 'r') as f:\n",
    "    class_names = [line.strip() for line in f]\n",
    "label_map = {i: name for i, name in enumerate(class_names)}\n",
    "\n",
    "# Modify the YAML data\n",
    "if 'train' in data:\n",
    "    data['train'] = 'train'\n",
    "if 'val' in data:\n",
    "    data['val'] = 'test'\n",
    "data['path'] = PEST_DATASET\n",
    "data['names'] = label_map\n",
    "data['nc'] = len(class_names)\n",
    "\n",
    "# Remove the 'download' key and value\n",
    "data.pop('download', None)\n",
    "data.pop('test', None)\n",
    "\n",
    "# Save the modified YAML file\n",
    "with open(NEW_YAML_PATH, 'w') as f:\n",
    "    yaml.dump(data, f, sort_keys=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train YOLOv5 Model\n",
    "\n",
    "  There is an import error due to a mismatch in the version of typing module. In Python 3.7, the OrderedDict is present in the collections module instead of the typing module.\n",
    "\n",
    "You can try the following solution:\n",
    "\n",
    ">Open the file maxvit.py located in `venv\\lib\\site-packages\\torchvision\\models` in a text editor.\n",
    "Change the import statement`from typing import Any, Callable, List, Optional, OrderedDict, Sequence, Tuple` to `from collections import OrderedDict`.\n",
    "Save the file and try running the train.py script again.\n",
    "If the above solution doesn't work, you can try to upgrade the version of PyTorch and torchvision using pip:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# %cd yolov5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# ! python train.py --img 640 --batch 16 --epochs 1 --data custom_data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    " # %cd .."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Try to Resume Training otherwise Start from Begining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5\\yolov5s.pt, cfg=, data=yolov5\\data\\coco128.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=100, batch_size=16, imgsz=640, rect=False, resume=True, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\\runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "YOLOv5  2023-5-12 Python-3.7.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir yolov5\\runs\\train', view at http://localhost:6006/\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mweights=yolov5s.pt, cfg=yolov5s.yaml, data=custom_data.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=1000, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=yolov5\\runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, img-size=640, batch=16, verbose=True\n",
      "YOLOv5  2023-5-12 Python-3.7.0 torch-1.13.1+cpu CPU\n",
      "\n",
      "\u001B[34m\u001B[1mhyperparameters: \u001B[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001B[34m\u001B[1mClearML: \u001B[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001B[34m\u001B[1mComet: \u001B[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir yolov5\\runs\\train', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     18879  models.yolo.Detect                      [2, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7025023 parameters, 7025023 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001B[34m\u001B[1malbumentations: \u001B[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\datasets\\pests\\train\\labels.cache... 5 images, 0 backgrounds, 0 corrupt: 100%|██████████| 5/5 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\datasets\\pests\\test\\labels... 4 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4/4 [00:11<00:00,  2.85s/it]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mWARNING  Cache directory C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\datasets\\pests\\test is not writeable: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\ACER\\\\Documents\\\\My mini Projects\\\\ML\\\\Betel Leaves\\\\datasets\\\\pests\\\\test\\\\labels.cache.npy' -> 'C:\\\\Users\\\\ACER\\\\Documents\\\\My mini Projects\\\\ML\\\\Betel Leaves\\\\datasets\\\\pests\\\\test\\\\labels.cache'\n",
      "\n",
      "\u001B[34m\u001B[1mAutoAnchor: \u001B[0m5.58 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to yolov5\\runs\\train\\exp2\\labels.jpg... \n",
      "Plotting labels to yolov5\\runs\\train\\exp4\\labels.jpg... \n",
      "Plotting labels to yolov5\\runs\\train\\exp2\\labels.jpg... \n",
      "Plotting labels to yolov5\\runs\\train\\exp5\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 5 dataloader workers\n",
      "Logging results to \u001B[1myolov5\\runs\\train\\exp5\u001B[0m\n",
      "Starting training for 1000 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/999         0G     0.1209     0.0394    0.03101         22        640: 100%|██████████| 1/1 [00:22<00:00, 22.28s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.16s/it]\n",
      "                   all          4         25    0.00143     0.0556    0.00104   0.000104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/999         0G     0.1276    0.05878    0.03187         60        640: 100%|██████████| 1/1 [00:05<00:00,  5.43s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]\n",
      "                   all          4         25     0.0038      0.111       0.07    0.00857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      2/999         0G     0.1277    0.05461    0.03216         54        640: 100%|██████████| 1/1 [00:04<00:00,  4.93s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:03<00:00,  3.41s/it]\n",
      "                   all          4         25          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      3/999         0G     0.1256    0.05076    0.03144         40        640: 100%|██████████| 1/1 [00:06<00:00,  6.22s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:03<00:00,  3.11s/it]\n",
      "                   all          4         25    0.00356      0.111    0.00913    0.00208\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      4/999         0G     0.1237    0.06202    0.03051         64        640: 100%|██████████| 1/1 [00:06<00:00,  6.50s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.81s/it]\n",
      "                   all          4         25    0.00355      0.111     0.0104    0.00196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      5/999         0G     0.1277    0.05256    0.03104         54        640: 100%|██████████| 1/1 [00:05<00:00,  5.20s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n",
      "                   all          4         25    0.00358      0.111    0.00583    0.00122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      6/999         0G     0.1244    0.04896    0.03156         38        640: 100%|██████████| 1/1 [00:05<00:00,  5.66s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n",
      "                   all          4         25    0.00173     0.0556    0.00898    0.00359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      7/999         0G     0.1217    0.04115    0.03106         28        640: 100%|██████████| 1/1 [00:05<00:00,  5.23s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n",
      "                   all          4         25    0.00167     0.0556     0.0103    0.00413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      8/999         0G     0.1268    0.06343     0.0312         78        640: 100%|██████████| 1/1 [00:04<00:00,  4.61s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "                   all          4         25    0.00162     0.0556    0.00251   0.000502\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      9/999         0G     0.1251    0.05378    0.03059         53        640: 100%|██████████| 1/1 [00:04<00:00,  4.66s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:03<00:00,  3.04s/it]\n",
      "                   all          4         25    0.00157     0.0556    0.00125    0.00025\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     10/999         0G     0.1235    0.05727     0.0323         70        640: 100%|██████████| 1/1 [00:05<00:00,  5.84s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:03<00:00,  3.15s/it]\n",
      "                   all          4         25    0.00155     0.0556    0.00106   0.000213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     11/999         0G     0.1253    0.04822    0.02997         41        640: 100%|██████████| 1/1 [00:05<00:00,  5.65s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.86s/it]\n",
      "                   all          4         25    0.00311      0.111    0.00216   0.000216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     12/999         0G     0.1212    0.04824    0.03177         51        640: 100%|██████████| 1/1 [00:05<00:00,  5.62s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:03<00:00,  3.01s/it]\n",
      "                   all          4         25    0.00464      0.167    0.00377   0.000377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     13/999         0G     0.1274    0.03833    0.03249         32        640: 100%|██████████| 1/1 [00:05<00:00,  5.68s/it]\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0%|          | 0/1 [00:00<?, ?it/s]WARNING  NMS time limit 0.700s exceeded\n",
      "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 1/1 [00:02<00:00,  2.57s/it]\n",
      "                   all          4         25          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "  0%|          | 0/1 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===============================================\n",
      "TRAINING RESUMED....\n",
      "===============================================\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\requirements.txt not found, check failed.\n",
      "Failed to Resume Training!!!\n",
      "\n",
      "===============================================\n",
      "TRAINING STARTED FROM Beginning....\n",
      "===============================================\n",
      "\u001B[34m\u001B[1mgithub: \u001B[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "\u001B[31m\u001B[1mrequirements:\u001B[0m C:\\Users\\ACER\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7028\\900571649.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'==============================================='\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 17\u001B[1;33m     \u001B[0mopt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresume\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     18\u001B[0m \u001B[1;32mexcept\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\yolov5\\train.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(**kwargs)\u001B[0m\n\u001B[0;32m    635\u001B[0m         \u001B[0msetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 636\u001B[1;33m     \u001B[0mmain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    637\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\yolov5\\train.py\u001B[0m in \u001B[0;36mmain\u001B[1;34m(opt, callbacks)\u001B[0m\n\u001B[0;32m    530\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevolve\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 531\u001B[1;33m         \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhyp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    532\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\yolov5\\train.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(hyp, opt, device, callbacks)\u001B[0m\n\u001B[0;32m    123\u001B[0m             \u001B[0mweights\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mattempt_download\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# download if not found locally\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 124\u001B[1;33m         \u001B[0mckpt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mweights\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'cpu'\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# load checkpoint to CPU to avoid CUDA memory leak\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    125\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcfg\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mckpt\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'model'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0myaml\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnc\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0manchors\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mhyp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'anchors'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# create\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\venv\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[0;32m    776\u001B[0m             \u001B[0morig_position\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtell\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 777\u001B[1;33m             \u001B[1;32mwith\u001B[0m \u001B[0m_open_zipfile_reader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mopened_zipfile\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    778\u001B[0m                 \u001B[1;32mif\u001B[0m \u001B[0m_is_torchscript_zip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopened_zipfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\venv\\lib\\site-packages\\torch\\serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, name_or_buffer)\u001B[0m\n\u001B[0;32m    281\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname_or_buffer\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 282\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_open_zipfile_reader\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_C\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mPyTorchFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    283\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: PytorchStreamReader failed reading zip archive: failed finding central directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_7028\\900571649.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'TRAINING STARTED FROM Beginning....'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'==============================================='\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m     \u001B[0mopt\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\yolov5\\train.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(**kwargs)\u001B[0m\n\u001B[0;32m    634\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    635\u001B[0m         \u001B[0msetattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mv\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 636\u001B[1;33m     \u001B[0mmain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    637\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    638\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\yolov5\\train.py\u001B[0m in \u001B[0;36mmain\u001B[1;34m(opt, callbacks)\u001B[0m\n\u001B[0;32m    529\u001B[0m     \u001B[1;31m# Train\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    530\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mevolve\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 531\u001B[1;33m         \u001B[0mtrain\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mopt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhyp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mopt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    532\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    533\u001B[0m     \u001B[1;31m# Evolve hyperparameters (optional)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\pest_detection\\yolov5\\train.py\u001B[0m in \u001B[0;36mtrain\u001B[1;34m(hyp, opt, device, callbacks)\u001B[0m\n\u001B[0;32m    318\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    319\u001B[0m             \u001B[1;31m# Backward\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 320\u001B[1;33m             \u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscale\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    321\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    322\u001B[0m             \u001B[1;31m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\venv\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    487\u001B[0m             )\n\u001B[0;32m    488\u001B[0m         torch.autograd.backward(\n\u001B[1;32m--> 489\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    490\u001B[0m         )\n\u001B[0;32m    491\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Documents\\My mini Projects\\ML\\Betel Leaves\\venv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    197\u001B[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0;32m    198\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 199\u001B[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[0;32m    200\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    201\u001B[0m def grad(\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from yolov5.train import run\n",
    "\n",
    "args = {\n",
    "    'img-size': 640,\n",
    "    'batch': 16,\n",
    "    'epochs': 1000,\n",
    "    'data': 'custom_data.yaml',\n",
    "    'cfg': 'yolov5s.yaml',\n",
    "    'weights': 'yolov5s.pt',\n",
    "    'verbose':True\n",
    "}\n",
    "\n",
    "try:\n",
    "    print('\\n\\n===============================================')\n",
    "    print('TRAINING RESUMED....')\n",
    "    print('===============================================')\n",
    "    opt = run(resume=True)\n",
    "except:\n",
    "    print('Failed to Resume Training!!!\\n\\n===============================================')\n",
    "    print('TRAINING STARTED FROM Beginning....')\n",
    "    print('===============================================')\n",
    "    opt = run(**args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from yolov5.utils.plots import plot_results\n",
    "import glob\n",
    "\n",
    "# get a list of all the experiment folders sorted by creation time\n",
    "exp_folders = sorted(glob.glob('./yolov5/runs/train/exp*/'), key=os.path.getmtime)\n",
    "\n",
    "try:\n",
    "    # get the last experiment folder\n",
    "    last_exp_folder = exp_folders[-1]\n",
    "\n",
    "    # get the path to the result.csv file in the last experiment folder\n",
    "    result_csv_path = os.path.join(last_exp_folder, 'results.csv')\n",
    "    result_png_path = os.path.join(last_exp_folder, 'results.png')\n",
    "\n",
    "    plot_results(result_csv_path)  # plot 'results.csv' as 'results.png'\n",
    "except AssertionError:\n",
    "    print('failed to open from last exp_folder. Opening the previous...')\n",
    "    # get the last experiment folder\n",
    "    last_exp_folder = exp_folders[-2]\n",
    "\n",
    "    # get the path to the result.csv file in the last experiment folder\n",
    "    result_csv_path = os.path.join(last_exp_folder, 'results.csv')\n",
    "    result_png_path = os.path.join(last_exp_folder, 'results.png')\n",
    "\n",
    "    plot_results(result_csv_path)  # plot 'results.csv' as 'results.png'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.read_csv(result_csv_path, index_col=False)\n",
    "print(f'YOLOv5 model has trained for {results_df.shape[0]} times.')\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # to show all columns\n",
    "results_df.head(-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=result_png_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}